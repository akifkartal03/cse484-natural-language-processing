{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "171044098.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "JfJ9Fw7vk0zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import re\n",
        "from google.colab import drive\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "G1Hz76hAS2j7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect Google Drive Account\n",
        "Please add files to the paths."
      ],
      "metadata": {
        "id": "YEC6kRNKk-KQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add corpus file to your google drive path is 'Colab Notebooks/data/corpus_out3.txt'\n",
        "#add test_sentence file to your google drive path is 'Colab Notebooks/data/test_sentences.txt'\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/My Drive/Colab Notebooks/data/corpus_out3.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eTjDVhoSuvU",
        "outputId": "e7b09b46-d1d1-41f8-d251-5c184d1883a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean data and remove noisy"
      ],
      "metadata": {
        "id": "42tJ0eBGlcyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_URL(text):\n",
        "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "    return url.sub(r\"\", text)\n",
        "\n",
        "\n",
        "def remove_html(text):\n",
        "    html = re.compile(r\"<.*?>\")\n",
        "    return html.sub(r\"\", text)\n",
        "\n",
        "\n",
        "file = open(path, 'r', encoding='utf-8')\n",
        "data1 = file.read()\n",
        "data1 = remove_URL(data1)\n",
        "data1 = remove_html(data1)\n",
        "data1 = data1.lower()\n",
        "data1 = data1.replace('\\n', '').replace('\\r', '')\n",
        "data = data1.split(\".\")\n",
        "data = np.array_split(data, 16)[0]\n",
        "\n",
        "print(len(data))\n",
        "print(data[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh4mXEC7Swgx",
        "outputId": "b8e8cffd-a6c9-4599-be20-58b595ab6daa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3425\n",
            "['bilgisayar işletim sistemlerinin en temel parçası olan çekirdek yazılımlarından bir tanesidir'\n",
            " ' gnu genel kamu lisansı ile sunulan ve linux vakfı çatısı altında geliştirilen bir özgür yazılım projesidir'\n",
            " ' linux ismi ilk geliştiricisi olan linus torvalds tarafından 1991 yılında verilmiştir'\n",
            " ' günümüzde süper bilgisayarlarda, akıllı cihazların ve internet altyapısında kullanılan cihazların işletim sistemlerinde yaygın olarak kullanılmaktadır'\n",
            " ' bunlardan en popüler olanı google tarafından geliştirilen android işletim sistemidir'\n",
            " 'ayrıca linux ismi, bu çekirdek kullanılarak oluşturulan işletim sistemlerini genel anlamda tanımlamak için yaygın bir kısaltma olarak da kullanılmaktadır'\n",
            " ' örneğin linux çekirdeği ve gnu araçları bir araya getirilerek tam bir işletim sistemi olarak sunulduğunda gnu/linux dağıtımı olarak adlandırılır, ancak konuşma dilinde kısaca linux olarak ifade edilmektedir'\n",
            " 'linux kelimesinin bu iki farklı kullanımının yol açabileceği karışıklıktan kaçınmak için çekirdek yazılım hakkındaki teknik bilgiler linux çekirdeği maddesinde, dağıtımlar hakkındaki bilgiler linux dağıtımları maddesinde verilmiştir'\n",
            " \"linux, 1991 yılında finlandiyalı bir üniversite öğrencisi olan linus torvalds tarafından, daha eski işletim sistemlerinden birisi olan unix'in mimarisine ve posix standartlarına uygun şekilde sıfırdan yazılamaya başlanmıştır\"\n",
            " \" geliştirilmesinde unix mimarisinden esinlenilmiş olmakla birlikte linux içinde unix'ten alınmış herhangi bir kod bulunmamaktadır\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into word tokens"
      ],
      "metadata": {
        "id": "AQaZXmGTljEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data)\n",
        "vocab = tokenizer.word_index\n",
        "seqs = tokenizer.texts_to_sequences(data)"
      ],
      "metadata": {
        "id": "28eOXbsnRQMJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare train data"
      ],
      "metadata": {
        "id": "i1JJsuCrl45C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sentence(seq, maxlen):\n",
        "    \n",
        "    x = []\n",
        "    y = []\n",
        "    for i, w in enumerate(seq):\n",
        "        x_padded = pad_sequences([seq[:i]],\n",
        "                                 maxlen=maxlen - 1,\n",
        "                                 padding='pre')[0]  \n",
        "        x.append(x_padded)\n",
        "        y.append(w)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "maxlen = max([len(seq) for seq in seqs])\n",
        "x = []\n",
        "y = []\n",
        "for seq in seqs:\n",
        "    x_windows, y_windows = prepare_sentence(seq, maxlen)\n",
        "    x += x_windows\n",
        "    y += y_windows\n",
        "x = np.array(x)\n",
        "y = np.array(y) - 1  \n",
        "y = np.eye(len(vocab))[y]  \n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axw7uqjSRVgJ",
        "outputId": "4cd12951-c1e2-4e1c-9fd1-eadeb33a434d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50581, 188)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tain model"
      ],
      "metadata": {
        "id": "xtK36ZkQmYlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(vocab) + 1,                    \n",
        "                    output_dim=5,  \n",
        "                    input_length=maxlen - 1))  \n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(len(vocab), activation='softmax'))\n",
        "model.compile('rmsprop', 'categorical_crossentropy')\n",
        "\n",
        "model.fit(x, y, epochs=1)\n",
        "\n",
        "\n",
        "#path='/content/drive/MyDrive/Colab Notebooks/model2/'\n",
        "#pickle.dump(model, open(path+'model30.pkl','wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIY2hiDpRcIy",
        "outputId": "c66e7722-c533-4e36-cab9-2cbddc260feb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317/317 [==============================] - 121s 371ms/step - loss: 8.7267 - val_loss: 9.0575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://516d0140-df5a-47df-a0a2-3499cb856c4d/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://516d0140-df5a-47df-a0a2-3499cb856c4d/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f879dc77790> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to Find best sentences"
      ],
      "metadata": {
        "id": "GhubHTyamkoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "name1 = '/content/drive/My Drive/Colab Notebooks/data/test_sentences.txt'\n",
        "in_testFile = open(name1, 'r', encoding='utf-8')\n",
        "\n",
        "english = [\"i\", \"o\", \"u\", \"s\", \"c\", \"g\"]\n",
        "turkish = {\"i\": \"ı\", \"o\": \"ö\", \"u\": \"ü\",\n",
        "                  \"s\": \"ş\", \"c\": \"ç\", \"g\": \"ğ\"}\n",
        "\n",
        "maxlen = max([len(seq) for seq in seqs])\n",
        "\n",
        "def prepare_sentence(seq, maxlen):\n",
        "    \n",
        "    x = []\n",
        "    y = []\n",
        "    for i, w in enumerate(seq):\n",
        "        x_padded = pad_sequences([seq[:i]],\n",
        "                                 maxlen=maxlen - 1,\n",
        "                                 padding='pre')[0]  \n",
        "        x.append(x_padded)\n",
        "        y.append(w)\n",
        "    return x, y\n",
        "\n",
        "def findPossibleSentences(sentence):\n",
        "\n",
        "    occurenceDict = dict()\n",
        "    resultSet = set()\n",
        "    resultSet.add(sentence)\n",
        "    size = 0\n",
        "    for ele in english:\n",
        "        occurenceDict[ele] = [m.start() for m in re.finditer(ele, sentence)]\n",
        "        size = size + len(occurenceDict[ele])\n",
        "\n",
        "    for key1, value1 in occurenceDict.items():\n",
        "        if len(value1) > 0:\n",
        "            for index in value1:\n",
        "                tempList = []\n",
        "                for sent in resultSet:\n",
        "                    liste = list(sent)\n",
        "                    liste[index] = turkish[key1]\n",
        "                    tempList.append(''.join(liste))\n",
        "                for item in tempList:\n",
        "                    resultSet.add(item)\n",
        "\n",
        "    return resultSet\n",
        "\n",
        "def writePerpToFile(sentence):\n",
        "    print(\"Best Sentence: \" + sentence)\n",
        "    print(\"------------------------------------------------\")\n",
        "  \n",
        "def findBestSentence():\n",
        "    allSentences = in_testFile.readlines()\n",
        "\n",
        "    for sent in allSentences:\n",
        "        possibles = findPossibleSentences(sent)\n",
        "        print(\"Test Sentence: \" + sent + \"Number of Possible Sentences: \" + str(len(possibles)))\n",
        "        \n",
        "        res = sent\n",
        "        min = get_results(res)\n",
        "        for item in possibles:\n",
        "            temp = get_results(item)\n",
        "            if  temp > min:\n",
        "                min = temp\n",
        "                res = item\n",
        "        writePerpToFile(res)\n",
        "            \n",
        "def get_results(sentence):\n",
        "    tok = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    x_test, y_test = prepare_sentence(tok, maxlen)\n",
        "    if len(x_test)== 0 :\n",
        "      return -sys.maxsize - 1\n",
        "    else:\n",
        "      x_test = np.array(x_test)\n",
        "      y_test = np.array(y_test) - 1  \n",
        "      \n",
        "      p_pred = model.predict(x_test)\n",
        "      \n",
        "      \n",
        "      vocab_inv = {v: k for k, v in vocab.items()}\n",
        "      log_p_sentence = 0\n",
        "      for i, prob in enumerate(p_pred):\n",
        "          word = vocab_inv[y_test[i]+1]  \n",
        "          prob_word = prob[y_test[i]]\n",
        "          log_p_sentence += np.log(prob_word)\n",
        "      return np.exp(log_p_sentence)\n",
        "    \n",
        "\n",
        "\n",
        "findBestSentence()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRc0sZQtgTHz",
        "outputId": "4c8a7517-bb45-49c4-8bfc-4a0144648f9f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Sentence: bilgisayar isletim sistemlerinin \n",
            "Number of Possible Sentences: 4096\n",
            "Best Sentence: bilgisayar işletım şistemlerınin \n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: ticari linux dagitimlarinin \n",
            "Number of Possible Sentences: 1024\n",
            "Best Sentence: tiçarı linux dağitimlarinin \n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: orta duzeyde zengin bir ailede \n",
            "Number of Possible Sentences: 64\n",
            "Best Sentence: örta duzeyde zenğin bir aılede \n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: yeni adiyla turkiye \n",
            "Number of Possible Sentences: 16\n",
            "Best Sentence: yeni adiyla turkiye \n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: ilde bircok etkinlik \n",
            "Number of Possible Sentences: 64\n",
            "Best Sentence: ilde birçok etkınlik \n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: cok sayida koyun yetistirilir\n",
            "Number of Possible Sentences: 2048\n",
            "Best Sentence: çok şayıda köyün yetıştırilir\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: beklenen olumlu tepkiyi alamadi\n",
            "Number of Possible Sentences: 64\n",
            "Best Sentence: beklenen olumlu tepkiyi alamadi\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: guzel vakit geciyor oneririm\n",
            "Number of Possible Sentences: 1024\n",
            "Best Sentence: güzel vakit ğeciyor önerırim\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: konforlu ve temiz bir yer\n",
            "Number of Possible Sentences: 32\n",
            "Best Sentence: könforlu ve temız bır yer\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: sicak ve eglenceli bir ortam\n",
            "Number of Possible Sentences: 256\n",
            "Best Sentence: şıcak ve eglençelı bır örtam\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: bu yurt okula cok uzak\n",
            "Number of Possible Sentences: 128\n",
            "Best Sentence: bu yürt oküla cök üzak\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: idare eder tavsiye ederim\n",
            "Number of Possible Sentences: 16\n",
            "Best Sentence: ıdare eder tavşiye ederim\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: fiyatlar cok pahali\n",
            "Number of Possible Sentences: 16\n",
            "Best Sentence: fıyatlar çok pahalı\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: oteller burdan ucuzdur\n",
            "Number of Possible Sentences: 64\n",
            "Best Sentence: oteller burdan ucuzdur\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: yurtda mutfak var is gorur\n",
            "Number of Possible Sentences: 128\n",
            "Best Sentence: yürtda mutfak var ıs ğorur\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: koskoca yurtda kutuphane yok\n",
            "Number of Possible Sentences: 256\n",
            "Best Sentence: koskoca yurtda kutuphane yok\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: nice dostluklarin kuruldugu yer\n",
            "Number of Possible Sentences: 2048\n",
            "Best Sentence: nice dostluklarin kuruldugu yer\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: cadirda kalirim daha iyi\n",
            "Number of Possible Sentences: 64\n",
            "Best Sentence: çadirda kalırim daha iyı\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: resimlere inanmayin bes para etmez\n",
            "Number of Possible Sentences: 32\n",
            "Best Sentence: resimlere inanmayin bes para etmez\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: cok bisey beklemeyin\n",
            "Number of Possible Sentences: 32\n",
            "Best Sentence: çok bışey beklemeyin\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: bu zamanda zor bulunacak bir yurt\n",
            "Number of Possible Sentences: 128\n",
            "Best Sentence: bü zamanda zör bulünaçak bır yürt\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: ogrenci dostu bir yurt\n",
            "Number of Possible Sentences: 512\n",
            "Best Sentence: oğrençı doştü bir yürt\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: calisanlarin davranislari cok iyi\n",
            "Number of Possible Sentences: 2048\n",
            "Best Sentence: calışanların davranısları çok ıyi\n",
            "\n",
            "------------------------------------------------\n",
            "Test Sentence: mac yayini yok bilginiz olsunNumber of Possible Sentences: 2048\n",
            "Best Sentence: maç yayini yök bılğıniz olşün\n",
            "------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}